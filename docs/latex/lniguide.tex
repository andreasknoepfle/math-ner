\documentclass{lni}

\IfFileExists{latin1.sty}{\usepackage{latin1}}{\usepackage{isolatin1}}

\usepackage{graphicx}
\usepackage{color}

\author{Andreas Knöpfle \& Tobias Schmid \\\\andreas.knoepfle@fu-berlin.de, tobias.schmid@fu-berlin.de}
\title{Eigennamenerkennung in mathematischen Texten}
\begin{document}
\maketitle

\begin{abstract}
abstract
\end{abstract}

\tableofcontents
\newpage
\pagestyle{plain}

\section{Einleitung}

Mit Hilfe einer Eigennamenerkennung ist es möglich Eigennamen in Texten zu finden. Es könnte beispielsweise interessant sein alle Personennamen in einem Text zu finden, um schnell herauszufinden, um wen es in diesem Text geht. Unterschiedliche Domänen haben meist auch unterschiedliche Eigennamen. In den einzelnen Domänen, wie z.B. die Mathematik, entstehen Eigennamen auf unterschiedliche Weisen. Wenn beispielsweise ein bekannter Mathematiker einen neuen Algorithmus entwickelt, so wird dieser oft nach dem Namen des Mathematikers benannt. Jedoch gibt es in den meisten Fällen keine eindeutigen Regeln, nach welchen Eigennamen entstehen und es ist somit nicht trivial diese Eigennamen in Texten zu finden. Eine Eigennamenerkennung aus einer bestimmten Domäne (z.B. die Biologie), funktioniert vermutlich auch nicht problemlos in einer anderen Domäne.\\

Es gibt schon verschiedene Eigennamenerkennungen in unterschiedlichen Domänen. Jedoch gibt es auch einige Domänen, für welche es noch keine bzw. nur ungenügend zufriedenstellende Eigennamenerkennungen gibt. Eine Domäne für welche es noch keine zufriedenstellende Eigennamenerkennung gibt, ist die Mathematik, mit welcher sich dieser Artikel beschäftigt.

\newpage
\section{Grundlagen}
In mathematischen Texten können Standart-Tools zur Erkennung von Eigennamen, wie die von Personen, Organisationen oder Orten nicht verwendet werden, da die Mathematik eigene Eigennamen definiert. Beispielsweise gibt es Formeln, Gleichungen oder Theoreme wie z.B. Satz des Pythagoras oder das Bayestheorem, die eigene Namen tragen und oft in mathematischen Texten vorkommen. Die Erkennung dieser Eigennamen wurde in dieser Arbeit mit zwei unterschiedlichen Ansätzen implementiert:
\begin{itemize}
	\item Regelbasierte Erkennung 
	\item Maschinelles Lernen
\end{itemize}
Bestehende Werkzeuge zur Eigennamenerkennung können zusätzlich zur eigentlichen Erkennung der Eigennamen Label vergeben, die die Erkannten Eigennamen typisieren (z.B. erhalten erkannte Personennamen ein Person-Label). Da es aber in der Mathematik sehr viele verschiedene Konzepte gibt und sich die mathematischen Eigennamen oft vielen Konzepten zuordnen lassen, wurde in dieser Arbeit auf eine zusätzliche Labelung der Eigenamen verzichtet. Die implementierten Ansätze verwenden daher jeweils ein gemeinsames Label ''MATH'' für mathematische Entitäten.

\subsection{Regelbasierte Erkennung}
\label{regex}
\begin{figure}[ht!]
\caption{Treebank Beispiel\label{penn}}
\small
\begin{verbatim}
(ROOT
  (S
    (PP (IN In)
      (ADJP (JJ particular)))
    (, ,)
    (NP (PRP$ our) (JJ colored) (NNS pebbles))
    (VP
      (VP (VB generalize)
        (CC and)
        (VB strengthen)
        (NP
          (NP (DT the) (JJ previous) (NNS results))
          (PP (IN of)
            (NP (NNP Lee)
              (CC and)
              (NNP Streinu)))))
      (CC and)
      (VP (VB give)
        (NP
          (NP (DT a) (JJ new) (NN proof))
          (PP (IN of)
            (NP
              (NP (DT the) (NNP Tutte-Nash-Williams) 
              	   (NN characterization))
              (PP (IN of)
                (NP (NN arboricity))))))))
    (. .)))
\end{verbatim}

\end{figure}
\normalsize

Das Erkennen der Eigennamen über reguläre Ausdrücken über einen längeren Text erfordert Satzbasierte Ausdrücke, die zusätzlich die Grammatik des Satzes einbeziehen. Dies führt zu sehr komplexen regulären Ausdrücken und erschwert das Erkennen der Eigennamen zusätzlich. Da Eigennamen immer nur in Nominalphrasen vorkommen, können die regulären Ausdrücke durch Vorverarbeitung des Textes wesentlich vereinfacht werden. Dazu wurde in dieser Arbeit der "Lexical Parser" der Stanford Natural Language Processing Group\footnote{http://nlp.stanford.edu/software/lex-parser.shtml} verwendet. 
\\
Dieser Parser baut einen Parse-Baum auf, der die syntaktische Struktur des eingegebenen Textes analysiert und den Text entsprechend annotiert. Dabei werden jedes Wort, zusammengehörige Wortgruppen und Satzteile annotiert. 
Abbildung \ref{penn} zeigt einen Beispielsatz der mit dem "Lexical Parser" analysiert und im Penn-Treebank Format\footnote{http://www.cis.upenn.edu/~treebank/} ausgegeben wurde.

Im Beispiel sind mehrere Nominalphrasen, wobei der Ausdruck  
\small
\begin{verbatim}(NP (DT the) (NNP Tutte-Nash-Williams) (NN characterization))
\end{verbatim} 
\normalsize
einen mathematischen Eigennamen enthält. 
Für die Erkennung der Eigennamen werden die durch den ''Lexical Parser'' erkannten Nominalphrasen mit Hilfe von Regulären Ausdrücken analysiert. Passt ein regulärer Ausdruck, kann die erkannte Nominalphrase im Text als Eigenname annotiert werden. Beim Annotieren werden zusätzlich vorrausgehende Artikel abgeschnitten.\\
Die regulären Ausdrücke sind dabei sehr einfach aufgebaut und suchen nach großgeschriebenen Wörtern, die zusammen mit einem oder mehreren kleingeschriebenen Wörtern (die keine Artikel oder Präpositionen sind) zusammen vorkommen.
\subsection{Erkennung mit maschinellem Lernen}
\label{mach-lern}
Für die Erkennung von mathematischen Eigennamen mit maschinellem Lernen wurde die Stanford Named Entity Recognition der Stanford Natural Language Processing Group\footnote{http://nlp.stanford.edu/ner/index.shtml} verwendet. \\
Bevor die mathematische Eigennamen erkannt werden können muss zunächst ein so genannter Korpus trainiert werden. Dafür benötigt man eine große Menge bereits von Textdaten mit annotierten Eigennamen. Mit einem Korpus der auf diese Weise trainiert wurde kann man anschließen auch neue Texte annotieren. \\
\begin{figure}[ht!]
  \begin{center}
  	\includegraphics[width=0.7\textwidth]{image/annotate.jpg}
  	\caption{Stanford simple manual annotation tool\label{annotate}}
  \end{center}
\end{figure}
Für das Annotieren der Trainingsdaten wurde das Stanford Annotation Tool\footnote{http://nlp.stanford.edu/software/stanford-manual-annotation-tool-2004-05-16.tar.gz} verwendet (siehe Abbildung \ref{annotate}). Dies ermögliche eine einfache Annotation von Eigennamen in Texten mit Hilfe von XML-Tags. 
\subsection{Datensatz}
Als Datensatz für die Evaluation und das Trainieren des maschinellen Lernens wurden Abstracts aus dem Arxiv.org-Datensatz\footnote{http://arxiv.org/} verwendet. Der Datensatz enthält Abstarcts aus den Themen Physik, Mathematik, Computer Science, Quantitative Biology, Quantitative Finance und Statistik. Für diese Arbeit wurden lediglich die Abstrakts verwendet, deren Thema in die Mathematik fällt. Der Arxiv Datensatz enthielt zum Zeitpunkt des Verfassens dieser Arbeit 145.800 Abstracts aus der Mathematik. Als Datenquelle wurde die XML-Version des Datensatzes verwendet.
\subsection{Architektur}
Zur Zwischenspeicherung der Abstarcts mit verschiedenen Annotationen verwendet die Implementierung die dokumentorientierte Datenbank MongoDB\footnote{http://www.mongodb.org/}. Jeweils ein MongoDB-Dokument enthält das Abstract in Rohform, die manuell annotierte Version des Abstracts (falls vorhanden) und das Ergebnis des Regelbasierten Verfahrens. 
\begin{figure}[ht!]
  \begin{center}
  	\includegraphics[width=0.7\textwidth]{image/arch.jpg}
  	\caption{Architektur der Evaluationsumgebung\label{arch}}
  \end{center}
\end{figure}
Abbildung \ref{arch} zeigt die grundsätzliche Architektur der Evaluationsumgebung. Der XML-Datensatz von arxiv.org wird mit Hilfe eines eigens entwickelten Parsers in die MongoDB-Datenbank importiert. Mit Hilfe einer modifizierten Version des Stanford Annotation Tools (siehe Abschnitt \ref{mach-lern}), in der Abbildung als ''Tagger'' gekennzeichnet, können annotierte Versionen der Abstracts erstellt werden. Das Modul zum annotieren der Eigennamen durch reguläre Ausdrücke, in der Abbildung als ''Regexer'' gekennzeichnet, kann ebenfalls annotierte Versionen der Abstracts erzeugen (siehe Abschnitt \ref{regex}). Dabei wird in beiden Fällen XML-annotierter Text erzeugt. \\Für das trainieren der Stanford Named Entity Recognition müssen die  XML-annotierten Texte in TSV-Format konviertiert werden, wobei eine Zeile immer ein Wort und das verwendete Label (in diesem Fall ''MATH'') oder ein Null-Label enthält. Diese Konvertierung kann durch das hier in der Abbildung als ''Converter'' bezeichnete Modul ausgeführt werden. \\
Zur Evaluierung der Verfahren wird das Perl-Skript ''colleval''\footnote{http://www.cnts.ua.ac.be/conll2000/chunking/conlleval.txt} verwendet. Dies erwartet ebenfalls ein TSV-Format, allerdings mit zwei Labeln pro Zeile (erwartetes Label und erkanntes Label). Diese Konvertierung kann durch das hier in der Abbildung als ''Eval'' bezeichnete Modul ausgeführt werden und verbindet die manuell annotierten Daten mit den Ergebnissen aus den jeweiligen Verfahren. \\

\subsection{Evaluationsmethoden}
\begin{figure}[ht!]
  \begin{center}
  	\includegraphics[width=1.0\textwidth]{image/eval.jpg}
  	\caption{Datenfluss der Evaluationsumgebung\label{eval}}
  \end{center}
\end{figure}


Für die Evaluation der Ergebnisse werden drei Maße verwendet:

\(Precision = \frac{Anzahl richtig getaggte Woerter}{Anzahl getaggte Woerter}\) 

\(Recall = \frac{Anzahl richtig getaggte Woerter}{Anzahl richtig getaggte Woerter + Anzahl nicht gefundene Woerter}\) 

\(F1 = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall}\)



\section{Analyse}

\subsection{Ergebnisse der Regelbasierte Erkennung}

Mit der Implementierung der regelbasierten Erkennung wurden folgende Ergebnisse erzielt:
\begin{list}{}{}
\item Precision:		95.27\% 
\item Recall:		49.55\% 
\item FB1-Maß:			57.97 
\end{list}

Folgende Details liegen diesem Ergebnis zu grunde:
\begin{list}{}{}
\item Anzahl Wörter in Testdatei:     	10077
\item Anzahl Wörter mit Tags:               664
\item Anzahl NER-getaggte Wörter:           471
\item Anzahl richtig NER-getaggte Wörter:   329
\end{list}

\subsubsection*{Nicht erkannte Eigennamen}


\subsubsection*{Falsch erkannte Eigennamen}



\subsection{Ergebnisse der Erkennung mit maschinellem Lernen}

Mit der Implementierung der Erkennung mit maschinellem Lernen wurden folgende Ergebnisse erzielt:
\begin{list}{}{}
\item Precision:		90.36\% 
\item Recall:		64.13\% 
\item FB1-Maß:		75.02
\end{list}

Folgende Details liegen diesem Ergebnis zu grunde:
\begin{list}{}{}
\item Anzahl Wörter in Testdatei:            11240
\item Anzahl Wörter mit Tags:                658
\item Anzahl NER-getaggte Wörter:            467
\item Anzahl richtig NER-getaggte Wörter:    422
\end{list}

\subsubsection*{Nicht erkannte Eigennamen}

There are 7622 isomorphism classes of smooth {\color{red}Fano polytopes} and 72256 isomorphism(...)

(...) quasi-isometric to {\color{red}Euclidean spaces} of arbitrary dimension ....

(...) is constructed based on {\color{red}L. Bers' theory of formal powers}.

(...) for the affine {\color{red}Weyl group symmetry}.   

(...) of equivariant {\color{green}Schubert classes} on {\color{red}Grassmannians} which implies(...)

(...) of the Fourier coefficients of {\color{green}Siegel modular} {\color{red}forms} on {\color{red}Maass Space} are obtained (...)

(...) modeling a {\color{green}Non-Newtonian fluid} {\color{red}of polymer aqueous solutions}.

(...) recall a {\color{red}theorem of Cantor} that (...) 

\subsubsection*{Falsch erkannte Eigennamen}

(...) the dual {\color{green}Feynman transform} {\color{red}whose algebras} are not necessarily (...)

(...) where {\color{green}Mathai's entropy} {\color{red}leads} to pathway (...)

(...) pricing continuous arithmetic average {\color{red}Asian options} in the (...)

(...) of the bacteria {\color{red}Staphylococcus aureus} in intermediate moisture (...)

(...) Food scientists at the {\color{red}U.S. Army's Natick Solider Center have} developed a model (...)

\section{Fazit}

\end{document}

