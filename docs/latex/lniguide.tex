\documentclass{lni}

\IfFileExists{latin1.sty}{\usepackage{latin1}}{\usepackage{isolatin1}}

\usepackage{graphicx}
\usepackage[usenames,dvipsnames]{xcolor}

\author{Andreas Knöpfle \& Tobias Schmid \\\\andreas.knoepfle@fu-berlin.de, tobias.schmid@fu-berlin.de}
\title{Erkennung von Eigennamen in mathematischen Texten}
\begin{document}
\maketitle

\begin{abstract}
In dieser Arbeit werden zwei verschiedene Ansätze für die Erkennung von Eigennamen in mathematischen Texten vorgestellt. Das erste Verfahren arbeitet mit Regulären Ausdrücken unter Zuhilfenahme der sprachlichen Syntax der Texte. Das zweite Verfahren arbeitet mit maschinellem Lernen. Beide Verfahren werden getrennt evaluiert. Im anschließenden Fazit werden die Verbesserungspotenziale beider Verfahren und mögliche Erweiterungen vorgestellt. 
\end{abstract}

\tableofcontents
\newpage
\pagestyle{plain}

\section{Einleitung}

Eigennamenerkennung ist Bestandteil des Gebiets der Informationsextraktion und macht es möglich Entitäten wie Personen, Organisationen und Ortsnamen in unstrukturierten Texten zu erkennen. Die Erkennung der Eigennamen erhöht dabei den Nützlichkeit der Texte erheblich \cite[1]{bunescu2007learning}.
Mit Hilfe von Eigennamenerkennung ist es möglich ähnliche Texte zu Textclustern zu gruppieren \cite[139]{sekine2009named} oder Texte mit enzyklopädischem Wissen zu verlinken. \\

Obwohl es bereits Ansätze für allgemeine Named Entity Recognition gibt, die über Sprachdomänen hinaus und sogar mit unterschiedlichen Sprachen funktionieren \cite{shared-ner} können mit Domänen- und Sprachspezifischen Eigennamenerkennungs-Methoden meißt bessere Ergebnisse erzielt werden.
Auf eine Domäne spezialisierte Verfahren sind zudem in der Lage die domänenspezifischen Eigennamen zu klassifizieren. Beispielsweise gibt es im Bereich der Biologie bereits Systeme zur Eigennamenerkennung von Proteinnamen oder chemischen Termen \cite{altman2002pacific}. Eine domainenspezifisches System zur Eigennamenerkennung, funktioniert allerdings auch nur bedinngt in einer anderen Domäne.\\

Eine Sprachdomäne für welche es noch keine zufriedenstellende Eigennamenerkennung gibt, ist die Mathematik, mit welcher sich dieser Artikel beschäftigt.

\newpage
\section{Grundlagen}
In mathematischen Texten können Standart-Tools zur Erkennung von Eigennamen, wie die von Personen, Organisationen oder Orten nicht verwendet werden, da die Mathematik eigene Eigennamen definiert. Beispielsweise gibt es Formeln, Gleichungen oder Theoreme wie z.B. Satz des Pythagoras oder das Bayestheorem, die eigene Namen tragen und oft in mathematischen Texten vorkommen. Die Erkennung dieser Eigennamen wurde in dieser Arbeit mit zwei unterschiedlichen Ansätzen implementiert:
\begin{itemize}
	\item Regelbasierte Erkennung 
	\item Maschinelles Lernen
\end{itemize}
Bestehende Werkzeuge zur Eigennamenerkennung können zusätzlich zur eigentlichen Erkennung der Eigennamen Label vergeben, die die Erkannten Eigennamen typisieren (z.B. erhalten erkannte Personennamen ein Person-Label). Da es aber in der Mathematik sehr viele verschiedene Konzepte gibt und sich die mathematischen Eigennamen oft vielen Konzepten zuordnen lassen, wurde in dieser Arbeit auf eine zusätzliche Labelung der Eigenamen verzichtet. Die implementierten Ansätze verwenden daher jeweils ein gemeinsames Label ''MATH'' für mathematische Entitäten.

\subsection{Regelbasierte Erkennung}
\label{regex}
\begin{figure}[ht!]
\caption{Treebank Beispiel\label{penn}}
\small
\begin{verbatim}
(ROOT
  (S
    (PP (IN In)
      (ADJP (JJ particular)))
    (, ,)
    (NP (PRP$ our) (JJ colored) (NNS pebbles))
    (VP
      (VP (VB generalize)
        (CC and)
        (VB strengthen)
        (NP
          (NP (DT the) (JJ previous) (NNS results))
          (PP (IN of)
            (NP (NNP Lee)
              (CC and)
              (NNP Streinu)))))
      (CC and)
      (VP (VB give)
        (NP
          (NP (DT a) (JJ new) (NN proof))
          (PP (IN of)
            (NP
              (NP (DT the) (NNP Tutte-Nash-Williams) 
              	   (NN characterization))
              (PP (IN of)
                (NP (NN arboricity))))))))
    (. .)))
\end{verbatim}

\end{figure}
\normalsize

Das Erkennen der Eigennamen über reguläre Ausdrücken über einen längeren Text erfordert Satzbasierte Ausdrücke, die zusätzlich die Grammatik des Satzes einbeziehen. Dies führt zu sehr komplexen regulären Ausdrücken und erschwert das Erkennen der Eigennamen zusätzlich. Da Eigennamen immer nur in Nominalphrasen vorkommen, können die regulären Ausdrücke durch Vorverarbeitung des Textes wesentlich vereinfacht werden. Dazu wurde in dieser Arbeit der "Lexical Parser" der Stanford Natural Language Processing Group\footnote{http://nlp.stanford.edu/software/lex-parser.shtml} verwendet. 
\\
Dieser Parser baut einen Parse-Baum auf, der die syntaktische Struktur des eingegebenen Textes analysiert und den Text entsprechend annotiert. Dabei werden jedes Wort, zusammengehörige Wortgruppen und Satzteile annotiert. 
Abbildung \ref{penn} zeigt einen Beispielsatz der mit dem "Lexical Parser" analysiert und im Penn-Treebank Format\footnote{http://www.cis.upenn.edu/~treebank/} ausgegeben wurde.

Im Beispiel sind mehrere Nominalphrasen, wobei der Ausdruck  
\small
\begin{verbatim}(NP (DT the) (NNP Tutte-Nash-Williams) (NN characterization))
\end{verbatim} 
\normalsize
einen mathematischen Eigennamen enthält. 
Für die Erkennung der Eigennamen werden die durch den ''Lexical Parser'' erkannten Nominalphrasen mit Hilfe von Regulären Ausdrücken analysiert. Passt ein regulärer Ausdruck, kann die erkannte Nominalphrase im Text als Eigenname annotiert werden. Beim Annotieren werden zusätzlich vorrausgehende Artikel abgeschnitten.\\
Die regulären Ausdrücke sind dabei sehr einfach aufgebaut und suchen nach großgeschriebenen Wörtern, die zusammen mit einem oder mehreren kleingeschriebenen Wörtern (die keine Artikel oder Präpositionen sind) zusammen vorkommen.
\subsection{Erkennung mit maschinellem Lernen}
\label{mach-lern}
Für die Erkennung von mathematischen Eigennamen mit maschinellem Lernen wurde die Stanford Named Entity Recognition der Stanford Natural Language Processing Group\footnote{http://nlp.stanford.edu/ner/index.shtml} verwendet. \\
Bevor die mathematische Eigennamen erkannt werden können muss zunächst ein so genannter Korpus trainiert werden. Dafür benötigt man eine große Menge bereits von Textdaten mit annotierten Eigennamen. Mit einem Korpus der auf diese Weise trainiert wurde kann man anschließen auch neue Texte annotieren. \\
\begin{figure}[ht!]
  \begin{center}
  	\includegraphics[width=0.7\textwidth]{image/annotate.jpg}
  	\caption{Stanford simple manual annotation tool\label{annotate}}
  \end{center}
\end{figure}
Für das Annotieren der Trainingsdaten wurde das Stanford Annotation Tool\footnote{http://nlp.stanford.edu/software/stanford-manual-annotation-tool-2004-05-16.tar.gz} verwendet (siehe Abbildung \ref{annotate}). Dies ermögliche eine einfache Annotation von Eigennamen in Texten mit Hilfe von XML-Tags. 
\subsection{Datensatz}
Als Datensatz für die Evaluation und das Trainieren des maschinellen Lernens wurden Abstracts aus dem Arxiv.org-Datensatz\footnote{http://arxiv.org/} verwendet. Der Datensatz enthält Abstarcts aus den Themen Physik, Mathematik, Computer Science, Quantitative Biology, Quantitative Finance und Statistik. Für diese Arbeit wurden lediglich die Abstrakts verwendet, deren Thema in die Mathematik fällt. Der Arxiv Datensatz enthielt zum Zeitpunkt des Verfassens dieser Arbeit 145.800 Abstracts aus der Mathematik. Als Datenquelle wurde die XML-Version des Datensatzes verwendet.
\subsection{Architektur}
\label{arch}
Im folgenden wird die Architektur der Evaluationsumgebung beschrieben\footnote{Das in der Arbeit beschriebene System ist unter https://github.com/andreasknoepfle/math-ner verfügbar.}.
Zur Zwischenspeicherung der Abstarcts mit verschiedenen Annotationen verwendet die Implementierung die dokumentorientierte Datenbank MongoDB\footnote{http://www.mongodb.org/}. Jeweils ein MongoDB-Dokument enthält das Abstract in Rohform, die manuell annotierte Version des Abstracts (falls vorhanden) und das Ergebnis des Regelbasierten Verfahrens. 
\begin{figure}[ht!]
  \begin{center}
  	\includegraphics[width=0.7\textwidth]{image/arch.jpg}
  	\caption{Architektur der Evaluationsumgebung\label{arch}}
  \end{center}
\end{figure}
Abbildung \ref{arch} zeigt die grundsätzliche Architektur der Evaluationsumgebung. Der XML-Datensatz von arxiv.org wird mit Hilfe eines eigens entwickelten Parsers in die MongoDB-Datenbank importiert. Mit Hilfe einer modifizierten Version des Stanford Annotation Tools (siehe Abschnitt \ref{mach-lern}), in der Abbildung als ''Tagger'' gekennzeichnet, können annotierte Versionen der Abstracts erstellt werden. Das Modul zum annotieren der Eigennamen durch reguläre Ausdrücke, in der Abbildung als ''Regexer'' gekennzeichnet, kann ebenfalls annotierte Versionen der Abstracts erzeugen (siehe Abschnitt \ref{regex}). Dabei wird in beiden Fällen XML-annotierter Text erzeugt. \\Für das trainieren der Stanford Named Entity Recognition müssen die  XML-annotierten Texte in TSV-Format konviertiert werden, wobei eine Zeile immer ein Wort und das verwendete Label (in diesem Fall ''MATH'') oder ein Null-Label enthält. Diese Konvertierung kann durch das hier in der Abbildung als ''Converter'' bezeichnete Modul ausgeführt werden. \\
Zur Evaluierung der Verfahren wird das Perl-Skript ''colleval''\footnote{http://www.cnts.ua.ac.be/conll2000/chunking/conlleval.txt} verwendet. Dies erwartet ebenfalls ein TSV-Format, allerdings mit zwei Labeln pro Zeile (erwartetes Label und erkanntes Label). Diese Konvertierung kann durch das hier in der Abbildung als ''Eval'' bezeichnete Modul ausgeführt werden und verbindet die manuell annotierten Daten mit den Ergebnissen aus den jeweiligen Verfahren. \\

\subsection{Evaluationsmethoden}
In Abbildung \ref{eval} ist der Prozess der Evaluation der Verfahren, des annotierens der Abstrakts und des trainieren des Korpus für das maschinelle Lernen vereinfacht dargestellt. Um die Evaluationsergebnisse des regelbasierten Verfahrens nicht zu verfälschen wurde das manuelle Annotieren der Abstracts, die zur Evaluation dieses Verfahrens benötigt werden, nur von einer externen, nicht am Entwickeln des Verfahrens beteiligten Person (in der Abbildung als ''Extern'' gekennzeichnet), durchgeführt.\\ 
Für das Trainieren des Korpus für das maschinelle Lernen wurden die Hälfte der manuell annotierten Daten verwendet. Die andere Hälfte wurde zur Evaluation dieses Verfahrens verwendet.   

\begin{figure}[ht!]
  \begin{center}
  	\includegraphics[width=1.0\textwidth]{image/eval.jpg}
  	\caption{Datenfluss der Evaluationsumgebung\label{eval}}
  \end{center}
\end{figure}

\newpage
Für die Evaluation der Ergebnisse werden drei Maße verwendet, die durch das bereits in Abschnitt \ref{arch} eingeführte colleval-Skript berechnet werden :
\vspace*{1cm}\\
$\mbox{Precision} = \frac{\mbox{Anzahl richtig getaggte Wörter}}{\mbox{Anzahl getaggte Wörter}}$
\vspace*{1cm}\\
$\mbox{Recall} = \frac{\mbox{Anzahl richtig getaggte Wörter}}{\mbox{Anzahl richtig getaggte Woerter} + \mbox{Anzahl nicht gefundene Wörter}}$ 
\vspace*{1cm}\\
$\mbox{FB1} = 2 \cdot \frac{\mbox{Precision} \cdot \mbox{Recall}}{\mbox{Precision} + \mbox{Recall}}$



\section{Analyse}
Folgender Abschnitt enthält die Ergebnisse der Evaluation beider Verfahren und Beispiele von durch die jeweiligen Verfahren nicht erkannten und falsch erkannten Eigennamen. Dabei sind für die nicht erkannten Eigennamen die nicht erkannten Teile {\color{red}rot} und die richtig erkannten Teile {\color{OliveGreen}grün} dargestellt. Für die falsch erkannten Eigennamen sind die falsch erkannten Teile {\color{red}rot} und die richtig erkannten Teile {\color{OliveGreen}grün} dargestellt.
\subsection{Ergebnisse der Regelbasierte Erkennung}

Mit der Implementierung der regelbasierten Erkennung wurden folgende Ergebnisse erzielt:
\begin{list}{}{}
\item Precision:		95.27\% 
\item Recall:		49.55\% 
\item FB1-Maß:			57.97 
\end{list}

Folgende Details liegen diesem Ergebnis zu grunde:
\begin{list}{}{}
\item Anzahl Wörter in Testdatei:     	10077
\item Anzahl Wörter mit Tags:               664
\item Anzahl NER-getaggte Wörter:           471
\item Anzahl richtig NER-getaggte Wörter:   329
\end{list}

\subsubsection*{Nicht erkannte Eigennamen}

(...) for {\color{red}nonabelian groups} and (...)

(...) of {\color{red}Kneser's theorem} follows (...)

(...) on {\color{red}Bol's condition for equality} (...)

(...) the {\color{red}Hessian} of the volume (...)

(...) a {\color{red}Schrödinger operator} on (...)
   
(...) {\color{red}Williams' decomposition} of the genealogy (...)

\subsubsection*{Falsch erkannte Eigennamen}

(...) of {\color{red}generically-unconventional} {\color{OliveGreen}Virasoro generators}    (...)

(...) again by {\color{red}Justin Roberts} as problem 12.18 in    (...)   

(...) on the {\color{red}second} {\color{OliveGreen}Minkowski inequality} (...)   

(... ) {\color{red}2-arc-transitive, arc-transitive and semisymmetric} {\color{OliveGreen}Levi graphs} (...)

(...) with the {\color{red}Directed Acyclic Graphs} (...)


\subsection{Ergebnisse der Erkennung mit maschinellem Lernen}

Mit der Implementierung der Erkennung mit maschinellem Lernen wurden folgende Ergebnisse erzielt:
\begin{list}{}{}
\item Precision:		90.36\% 
\item Recall:		64.13\% 
\item FB1-Maß:		75.02
\end{list}

Folgende Details liegen diesem Ergebnis zu grunde:
\begin{list}{}{}
\item Anzahl Wörter in Testdatei:            11240
\item Anzahl Wörter mit Tags:                658
\item Anzahl NER-getaggte Wörter:            467
\item Anzahl richtig NER-getaggte Wörter:    422
\end{list}

\subsubsection*{Nicht erkannte Eigennamen}

There are 7622 isomorphism classes of smooth {\color{red}Fano polytopes} and 72256 isomorphism(...)

(...) quasi-isometric to {\color{red}Euclidean spaces} of arbitrary dimension ....

(...) is constructed based on {\color{red}L. Bers' theory of formal powers}.

(...) for the affine {\color{red}Weyl group symmetry}.   

(...) of equivariant {\color{OliveGreen}Schubert classes} on {\color{red}Grassmannians} which implies(...)

(...) of the Fourier coefficients of {\color{OliveGreen}Siegel modular} {\color{red}forms} on {\color{red}Maass Space} are obtained (...)

(...) modeling a {\color{OliveGreen}Non-Newtonian fluid} {\color{red}of polymer aqueous solutions}.

(...) recall a {\color{red}theorem of Cantor} that (...) 

\subsubsection*{Falsch erkannte Eigennamen}

(...) the dual {\color{OliveGreen}Feynman transform} {\color{red}whose algebras} are not necessarily (...)

(...) where {\color{OliveGreen}Mathai's entropy} {\color{red}leads} to pathway (...)

(...) pricing continuous arithmetic average {\color{red}Asian options} in the (...)

(...) of the bacteria {\color{red}Staphylococcus aureus} in intermediate moisture (...)

(...) Food scientists at the {\color{red}U.S. Army's Natick Solider Center have} developed a model (...)

\section{Fazit}
Beide Verfahren erreichen bereits hohe Precision-Maße und das Recall-Maß ist in beiden Verfahren ebenfalls weit über 50\%, obwohl beide Verfahren noch Spielraum für Optimierungen bieten.
\subsection{Fazit regelbasierte Erkennung}
\label{fazitreg}
Das regelbasierte Verfahren hat mit über 95\% bereits eine sehr hohe Präzision und erkannte Begriffe sind sehr selten falsch erkannt.
Allerdings können kleingeschriebene Eigennamen noch nicht erkannt werden. Dies könnte durch eine Mischung des bisherigen Verfahren mit Schlüsselwörterlisten von Mathematischen Konzepten nachgerüstet werden.
Das Verfahren annotiert zusätzliche Adjektive, die nicht zum Eigennamen gehören. Dies könnte durch hinzuziehen der Informationen aus dem Parsebaum des ''Lexical Parser'' ebenfalls behoben werden (ähnlich wie Artikel). \\
Der ''Lexical Parser'' führt zudem einen großen Rechenaufwand ein, durch die das Verfahren deutlich langsamer als die Erkennung durch maschinelles Lernen  wird. \\
Zudem ist eine Unterscheidung von mathematische Eigennamen und Personen-Eigennamen nicht einfach möglich, wenn kein zusätzliches Schlüsselwort im Text den mathematischen Eigennamen begleitet.
\subsection{Fazit maschinelles Lernen}
Diese Methode erkennt auch kleingeschriebene Eigennamen. Allerdings werden oft den Eigennamen nachfolgende Wörter mit annotiert.
Allerding erkennt das Verfahren auch Eigennamen aus anderen Sprach-Domainen die z.B. in der Einleitung der Texte vorkommen können.
Darüber hinaus konnte man feststellen, das sich das Verfahren mit zunehmender Menge an annotierten Trainingsdaten immer weiter verbessert hat.
\subsection{Erweiterungen und Ausblick}
Mit den bereits im Abschnitt \ref {fazitreg} erwähnten Verbesserungen des regelbasierten Verfahrens und weiteren Regulären Ausdrücken lässt sich dieses Verfahren noch weiter verbesseren. Ebenso könnte durch Anpassungen der Einstellungen am Stanford NER und einer größeren Menge von Trainingsdaten auch das Verfahren mit maschinellem Lernen Verbessert werden.\\
Weiterhin könnte durch Kombination beider Verfahren ein Hybrides Verfahren eventuell mehr leisten.


\bibliography{sources}


\end{document}

